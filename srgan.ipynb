{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10634837,"sourceType":"datasetVersion","datasetId":6584451},{"sourceId":10636715,"sourceType":"datasetVersion","datasetId":6585716},{"sourceId":10643951,"sourceType":"datasetVersion","datasetId":6590540},{"sourceId":10700442,"sourceType":"datasetVersion","datasetId":6631100},{"sourceId":10764989,"sourceType":"datasetVersion","datasetId":6677678},{"sourceId":10765791,"sourceType":"datasetVersion","datasetId":6678288}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model, load_model\nfrom keras.layers import (Conv2D, Lambda, LeakyReLU, Dense, Input, add, concatenate, Flatten, BatchNormalization, PReLU, UpSampling2D)\nfrom keras.applications.vgg19 import VGG19, preprocess_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:58:01.945589Z","iopub.execute_input":"2025-02-17T18:58:01.945897Z","iopub.status.idle":"2025-02-17T18:58:14.376529Z","shell.execute_reply.started":"2025-02-17T18:58:01.945870Z","shell.execute_reply":"2025-02-17T18:58:14.375917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Helper Function to Convert BGR -> RGB for Display ---\ndef bgr_to_rgb(image):\n    \"\"\"Convert a BGR image (H,W,3) to RGB for display purposes.\"\"\"\n    return image[..., ::-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:22:10.634571Z","iopub.execute_input":"2025-02-17T18:22:10.635006Z","iopub.status.idle":"2025-02-17T18:22:10.638923Z","shell.execute_reply.started":"2025-02-17T18:22:10.634973Z","shell.execute_reply":"2025-02-17T18:22:10.637970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Learning Rate Schedule ---\ndef lr_schedule(epoch):\n    if epoch < 15: return 1e-5  # Warmup\n    elif epoch < 50: return 1e-4\n    else: return 1e-4 * (0.95 ** (epoch//10))\n        \n# Initialize optimizers \ngen_optimizer = tf.keras.optimizers.Adam(1e-4)\ndisc_optimizer = tf.keras.optimizers.Adam(1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:50:23.795428Z","iopub.execute_input":"2025-02-17T18:50:23.795860Z","iopub.status.idle":"2025-02-17T18:50:23.808216Z","shell.execute_reply.started":"2025-02-17T18:50:23.795831Z","shell.execute_reply":"2025-02-17T18:50:23.807285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SRGAN Model Components\n\ndef residual_block(x):\n    res = Conv2D(64, 3, padding='same')(x)\n    res = PReLU(shared_axes=[1,2])(res)  # Removed BatchNorm\n    res = Conv2D(64, 3, padding='same')(res)\n    return add([x, res])\n\ndef srgan_generator():\n    inputs = Input((64,64,3))\n    x = Conv2D(64, 3, padding='same')(inputs)\n    x = PReLU(shared_axes=[1,2])(x)\n    temp = x\n    \n    # 16 Residual Blocks\n    for _ in range(16):\n        x = residual_block(x)\n    \n    x = Conv2D(64, 3, padding='same')(x)\n    x = add([x, temp])\n    \n    # Upsampling\n    x = UpSampling2D()(x)\n    x = Conv2D(256, 3, padding='same')(x)\n    x = PReLU(shared_axes=[1,2])(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2D(256, 3, padding='same')(x)\n    x = PReLU(shared_axes=[1,2])(x)\n    \n    outputs = Conv2D(3, 3, padding='same', activation='sigmoid')(x)\n    return Model(inputs, outputs)\n\ndef srgan_discriminator():\n    inputs = Input((256, 256, 3))\n    x = Conv2D(64, 3, padding='same')(inputs)\n    x = LeakyReLU(alpha=0.2)(x)  # Use LeakyReLU layer from Keras\n    \n    # Feature extraction\n    for filters in [64, 128, 256, 512]:\n        x = Conv2D(filters, 3, strides=2, padding='same')(x)\n        x = LeakyReLU(alpha=0.2)(x)  # Use LeakyReLU layer here too\n        x = Conv2D(filters, 3, padding='same')(x)\n        x = LeakyReLU(alpha=0.2)(x)  # Use LeakyReLU layer here as well\n    \n    # Decision layer\n    x = Flatten()(x)\n    x = Dense(1024)(x)\n    x = LeakyReLU(alpha=0.2)(x)  # LeakyReLU for dense layer\n    outputs = Dense(1)(x)  # No sigmoid\n    return Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:25:22.670574Z","iopub.execute_input":"2025-02-17T18:25:22.670938Z","iopub.status.idle":"2025-02-17T18:25:22.679212Z","shell.execute_reply.started":"2025-02-17T18:25:22.670908Z","shell.execute_reply":"2025-02-17T18:25:22.678224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VGG19 Feature Extractor: \ndef build_vgg():\n    vgg = VGG19(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))\n    \n    # Specify the layer from which you want to extract features\n    block5_conv4 = vgg.get_layer(\"block5_conv4\").output  # Deeper features\n    \n    # Create a new model with the original input and the new output\n    vgg_model = Model(inputs=vgg.input, outputs=block5_conv4)\n    \n    return vgg_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:26:42.777621Z","iopub.execute_input":"2025-02-17T18:26:42.777943Z","iopub.status.idle":"2025-02-17T18:26:42.782397Z","shell.execute_reply.started":"2025-02-17T18:26:42.777921Z","shell.execute_reply":"2025-02-17T18:26:42.781559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combined model for perceptual loss\ndef create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n    gen_img = gen_model(lr_ip)\n    gen_features = vgg(gen_img)\n    disc_model.trainable = False\n    validity = disc_model(gen_img)\n    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:25:25.153222Z","iopub.execute_input":"2025-02-17T18:25:25.153595Z","iopub.status.idle":"2025-02-17T18:25:25.157887Z","shell.execute_reply.started":"2025-02-17T18:25:25.153562Z","shell.execute_reply":"2025-02-17T18:25:25.156981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Loading\nn = 5000  # Number of images to use\nlr_path = \"/kaggle/input/sr-data/DATASET/AUG/LR_Aug\"\nhr_path = \"/kaggle/input/sr-data/DATASET/AUG/HR_Aug\"\n\nlr_list = os.listdir(lr_path)[:n]\nhr_list = os.listdir(hr_path)[:n]\n\nlr_images = []\nhr_images = []\n\n# Load images and keep them in BGR (for VGG)\nfor img in lr_list:\n    img_path = os.path.join(lr_path, img)\n    img_lr = cv2.imread(img_path)  # BGR format\n    lr_images.append(img_lr)\n\nfor img in hr_list:\n    img_path = os.path.join(hr_path, img)\n    img_hr = cv2.imread(img_path)  # BGR format\n    hr_images.append(img_hr)\n\nlr_images = np.array(lr_images, dtype=np.float32) / 255.0\nhr_images = np.array(hr_images, dtype=np.float32) / 255.0\n\nprint(f\"LR shape: {lr_images[0].shape}, HR shape: {hr_images[0].shape}\")\nprint(f\"LR range: [{lr_images.min()}, {lr_images.max()}]\")\nprint(f\"HR range: [{hr_images.min()}, {hr_images.max()}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:22:50.939140Z","iopub.execute_input":"2025-02-17T18:22:50.939441Z","iopub.status.idle":"2025-02-17T18:23:01.699768Z","shell.execute_reply.started":"2025-02-17T18:22:50.939418Z","shell.execute_reply":"2025-02-17T18:23:01.698848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing Random Images\nrandom_idx = random.randint(0, len(lr_images)-1)\nplt.figure(figsize=(8,8))\nplt.subplot(2, 2, 1)\nplt.imshow(bgr_to_rgb(lr_images[random_idx]))\nplt.title(\" LR Sample \")\nplt.axis(\"off\")\nplt.subplot(2, 2, 2)\nplt.imshow(bgr_to_rgb(hr_images[random_idx]))\nplt.title(\" HR Sample \")\nplt.axis(\"off\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:23:01.700870Z","iopub.execute_input":"2025-02-17T18:23:01.701106Z","iopub.status.idle":"2025-02-17T18:23:01.891953Z","shell.execute_reply.started":"2025-02-17T18:23:01.701087Z","shell.execute_reply":"2025-02-17T18:23:01.890919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-test split\nlr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, test_size=0.33, random_state=42)\nhr_shape = (256,256,3)\nlr_shape = (64,64,3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:25:28.266405Z","iopub.execute_input":"2025-02-17T18:25:28.266763Z","iopub.status.idle":"2025-02-17T18:25:28.625897Z","shell.execute_reply.started":"2025-02-17T18:25:28.266733Z","shell.execute_reply":"2025-02-17T18:25:28.624922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Model Initialization ---\n# Initialize models\ngenerator = srgan_generator()\ngenerator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:25:29.046706Z","iopub.execute_input":"2025-02-17T18:25:29.047096Z","iopub.status.idle":"2025-02-17T18:25:29.427409Z","shell.execute_reply.started":"2025-02-17T18:25:29.047063Z","shell.execute_reply":"2025-02-17T18:25:29.426592Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"discriminator = srgan_discriminator()\ndiscriminator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:25:32.694386Z","iopub.execute_input":"2025-02-17T18:25:32.694731Z","iopub.status.idle":"2025-02-17T18:25:32.815740Z","shell.execute_reply.started":"2025-02-17T18:25:32.694706Z","shell.execute_reply":"2025-02-17T18:25:32.815056Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vgg = build_vgg() \nvgg.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:26:47.413388Z","iopub.execute_input":"2025-02-17T18:26:47.413744Z","iopub.status.idle":"2025-02-17T18:26:47.715855Z","shell.execute_reply.started":"2025-02-17T18:26:47.413714Z","shell.execute_reply":"2025-02-17T18:26:47.714707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training Parameters\nbatch_size = 6\nepochs = 100  # Adjust as needed\ntrain_dataset = tf.data.Dataset.from_tensor_slices((lr_train, hr_train)).batch(batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:26:48.771063Z","iopub.execute_input":"2025-02-17T18:26:48.771431Z","iopub.status.idle":"2025-02-17T18:26:50.801381Z","shell.execute_reply.started":"2025-02-17T18:26:48.771378Z","shell.execute_reply":"2025-02-17T18:26:50.800548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss tracking lists\ngen_losses = []\ndisc_losses = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:26:50.802489Z","iopub.execute_input":"2025-02-17T18:26:50.802773Z","iopub.status.idle":"2025-02-17T18:26:50.806490Z","shell.execute_reply.started":"2025-02-17T18:26:50.802747Z","shell.execute_reply":"2025-02-17T18:26:50.805523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Training Loop\nfor epoch in range(epochs):\n    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n    \n    # Initialize loss for this epoch\n    epoch_gen_loss = 0\n    epoch_disc_loss = 0\n    \n    # Add tqdm for progress bar in the batch loop\n    for lr_batch, hr_batch in tqdm(tf.data.Dataset.from_tensor_slices((lr_train, hr_train)).batch(batch_size), \n                                    total=len(lr_train) // batch_size, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n        # Discriminator Training\n        with tf.GradientTape() as disc_tape:\n            fake_hr = generator(lr_batch)\n            real_output = discriminator(hr_batch)\n            fake_output = discriminator(fake_hr)\n            \n            # Hinge loss\n            disc_loss = tf.reduce_mean(tf.nn.relu(1.0 - real_output)) + \\\n                       tf.reduce_mean(tf.nn.relu(1.0 + fake_output))\n        \n        disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n        disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n        \n        # Generator Training\n        with tf.GradientTape() as gen_tape:\n            fake_hr = generator(lr_batch)\n            gen_features = vgg(fake_hr)\n            real_features = vgg(hr_batch)\n            \n            # Content loss (MSE in feature space)\n            content_loss = tf.reduce_mean(tf.abs(gen_features - real_features))\n            \n            # Adversarial loss (Discriminator feedback)\n            adv_loss = -tf.reduce_mean(discriminator(fake_hr))\n            \n            gen_loss = content_loss + 1e-3 * adv_loss  # Weights for balancing content vs. adversarial loss\n        \n        gen_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n        gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n        \n        # Accumulate losses\n        epoch_gen_loss += gen_loss\n        epoch_disc_loss += disc_loss\n    \n    # Append average loss for this epoch\n    gen_losses.append(epoch_gen_loss / len(lr_train))\n    disc_losses.append(epoch_disc_loss / len(lr_train))\n    \n    # Optionally: Print out the average losses per epoch\n    print(f\"Epoch {epoch+1} - Generator Loss: {gen_losses[-1]}, Discriminator Loss: {disc_losses[-1]}\")\n\n# Save final generator\ngenerator.save(\"srgan_generator_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:33:25.466838Z","iopub.execute_input":"2025-02-17T18:33:25.467160Z","iopub.status.idle":"2025-02-17T18:45:56.315816Z","shell.execute_reply.started":"2025-02-17T18:33:25.467135Z","shell.execute_reply":"2025-02-17T18:45:56.314607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generator.save(\"srgan_generator_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:45:56.317287Z","iopub.execute_input":"2025-02-17T18:45:56.317663Z","iopub.status.idle":"2025-02-17T18:45:56.435167Z","shell.execute_reply.started":"2025-02-17T18:45:56.317630Z","shell.execute_reply":"2025-02-17T18:45:56.434161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation Metrics\ndef evaluate_gan(generator, lr_test, hr_test, batch_size=8):\n    psnr_values = []\n    ssim_values = []\n    mse_values = []\n    lr_samples = []\n    hr_samples = []\n    sr_samples = []\n    \n    for i in tqdm(range(0, len(lr_test), batch_size), desc=\"Generating SR images\"):\n        lr_batch = lr_test[i:i+batch_size]\n        hr_batch = hr_test[i:i+batch_size]\n        \n        sr_batch = generator.predict(lr_batch, verbose=0)\n        sr_batch = np.clip(sr_batch, 0.0, 1.0)\n        \n        for j in range(len(hr_batch)):\n            psnr_val = psnr(hr_batch[j], sr_batch[j], data_range=1.0)\n            ssim_val = ssim(hr_batch[j], sr_batch[j], data_range=1.0, channel_axis=-1)\n            mse_val = np.mean((hr_batch[j] - sr_batch[j]) ** 2)\n            \n            psnr_values.append(psnr_val)\n            ssim_values.append(ssim_val)\n            mse_values.append(mse_val)\n        \n        lr_samples.extend(lr_batch)\n        hr_samples.extend(hr_batch)\n        sr_samples.extend(sr_batch)\n    \n    return {\n        'psnr': psnr_values,\n        'ssim': ssim_values,\n        'mse': mse_values,\n        'lr_samples': np.array(lr_samples),\n        'hr_samples': np.array(hr_samples),\n        'sr_samples': np.array(sr_samples)\n    }\n\ngan_metrics = evaluate_gan(generator, lr_test, hr_test)\nprint(\"Mean PSNR:\", np.mean(gan_metrics['psnr']))\nprint(\"Mean SSIM:\", np.mean(gan_metrics['ssim']))\nprint(\"Mean MSE: \", np.mean(gan_metrics['mse']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:45:56.436926Z","iopub.execute_input":"2025-02-17T18:45:56.437187Z","iopub.status.idle":"2025-02-17T18:46:30.713735Z","shell.execute_reply.started":"2025-02-17T18:45:56.437160Z","shell.execute_reply":"2025-02-17T18:46:30.712862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss Visualization\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, epochs+1), gen_losses, color='blue', marker='o', label='Generator Loss')\nplt.title('Generator Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, epochs+1), disc_losses, color='orange', marker='o', label='Discriminator Loss')\nplt.title('Discriminator Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:46:30.714905Z","iopub.execute_input":"2025-02-17T18:46:30.715200Z","iopub.status.idle":"2025-02-17T18:46:31.065440Z","shell.execute_reply.started":"2025-02-17T18:46:30.715176Z","shell.execute_reply":"2025-02-17T18:46:31.064795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sample Comparisons\ndef plot_gan_samples(gan_metrics, num_samples=3):\n    indices = np.random.choice(len(gan_metrics['lr_samples']), num_samples)\n    for idx in indices:\n        plt.figure(figsize=(12,6))\n        # LR Input (BGR -> RGB for display)\n        plt.subplot(241)\n        lr_bgr = gan_metrics['lr_samples'][idx]\n        plt.imshow(bgr_to_rgb(lr_bgr))\n        plt.title('LR Input')\n        plt.axis('off')\n        \n        # HR Target (BGR -> RGB for display)\n        plt.subplot(242)\n        hr_bgr = gan_metrics['hr_samples'][idx]\n        plt.imshow(bgr_to_rgb(hr_bgr))\n        plt.title('HR Target')\n        plt.axis('off')\n        \n        # SR Output (BGR -> RGB for display)\n        plt.subplot(243)\n        sr_bgr = gan_metrics['sr_samples'][idx]\n        metrics_text = f\"PSNR: {gan_metrics['psnr'][idx]:.2f}\\nSSIM: {gan_metrics['ssim'][idx]:.4f}\\nMSE: {gan_metrics['mse'][idx]:.5f}\"\n        plt.imshow(bgr_to_rgb(sr_bgr))\n        plt.title('SRGAN Output\\n' + metrics_text)\n        plt.axis('off')\n        \n        # Error Map\n        plt.subplot(244)\n        error = np.abs(hr_bgr - sr_bgr)\n        plt.imshow(np.mean(error, axis=-1), cmap='inferno', vmin=0, vmax=0.07)\n        plt.title('Pixel Error Heatmap')\n        plt.colorbar()\n        plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n\nplot_gan_samples(gan_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:46:31.066118Z","iopub.execute_input":"2025-02-17T18:46:31.066320Z","iopub.status.idle":"2025-02-17T18:46:32.321389Z","shell.execute_reply.started":"2025-02-17T18:46:31.066302Z","shell.execute_reply":"2025-02-17T18:46:32.320495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Metric Distributions\ndef plot_gan_metrics(gan_metrics):\n    fig, axs = plt.subplots(1, 3, figsize=(18,5))\n    metrics = ['psnr', 'ssim', 'mse']\n    titles = ['PSNR Distribution', 'SSIM Distribution', 'MSE Distribution']\n    colors = ['purple', 'green', 'red']\n    for ax, metric, title, color in zip(axs, metrics, titles, colors):\n        ax.hist(gan_metrics[metric], bins=30, alpha=0.7, color=color)\n        ax.set_title(title)\n        ax.set_xlabel(metric.upper())\n        ax.set_ylabel('Frequency')\n        mean_val = np.mean(gan_metrics[metric])\n        ax.axvline(mean_val, color='black', linestyle='dashed', linewidth=2, label=f'Mean: {mean_val:.2f}')\n        ax.legend()\n    plt.tight_layout()\n    plt.show()\n\nplot_gan_metrics(gan_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:46:32.322311Z","iopub.execute_input":"2025-02-17T18:46:32.322631Z","iopub.status.idle":"2025-02-17T18:46:33.029978Z","shell.execute_reply.started":"2025-02-17T18:46:32.322603Z","shell.execute_reply":"2025-02-17T18:46:33.029025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Error Analysis\ndef plot_gan_error_analysis(gan_metrics):\n    fig, axs = plt.subplots(1, 2, figsize=(12,5))\n    errors = np.concatenate([np.abs(hr - sr) for hr, sr in zip(gan_metrics['hr_samples'], gan_metrics['sr_samples'])])\n    axs[0].hist(errors.flatten(), bins=50, color='darkorange', density=True)\n    axs[0].set_title('Pixel Error Distribution')\n    axs[0].set_xlabel('Absolute Error')\n    axs[0].set_ylabel('Density')\n    \n    axs[1].scatter(gan_metrics['psnr'], gan_metrics['ssim'], alpha=0.5)\n    axs[1].set_title('PSNR vs SSIM Correlation')\n    axs[1].set_xlabel('PSNR')\n    axs[1].set_ylabel('SSIM')\n    \n    psnr_data = np.array(gan_metrics['psnr'])\n    ssim_data = np.array(gan_metrics['ssim'])\n    X = psnr_data.reshape(-1, 1)\n    y = ssim_data\n    m, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n    \n    x_line = np.linspace(0, psnr_data.max(), 100)\n    y_line = m[0] * x_line\n    axs[1].plot(x_line, y_line, color='red', linestyle='--', label=f'Trend: y = {m[0]:.5f}x')\n    axs[1].legend()\n    plt.tight_layout()\n    plt.show()\n\nplot_gan_error_analysis(gan_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:46:33.030874Z","iopub.execute_input":"2025-02-17T18:46:33.031140Z","iopub.status.idle":"2025-02-17T18:46:35.411108Z","shell.execute_reply.started":"2025-02-17T18:46:33.031117Z","shell.execute_reply":"2025-02-17T18:46:35.410172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#----Test with New Dataset ----","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:46:35.412851Z","iopub.execute_input":"2025-02-17T18:46:35.413084Z","iopub.status.idle":"2025-02-17T18:46:35.416234Z","shell.execute_reply.started":"2025-02-17T18:46:35.413064Z","shell.execute_reply":"2025-02-17T18:46:35.415529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define new test dataset directories\nnew_lr_dir = \"/kaggle/input/test-sr/testing dataset/LR\"\nnew_hr_dir = \"/kaggle/input/test-sr/testing dataset/HR\"\n\n# Helper function to load images in RGB (for SRGAN)\ndef load_images_rgb(folder, resize_shape):\n    filenames = sorted(os.listdir(folder))\n    images = []\n    for file in filenames:\n        path = os.path.join(folder, file)\n        img = cv2.imread(path)\n        if img is not None:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, resize_shape)\n            images.append(img.astype(np.float32) / 255.0)\n    return np.array(images)\n\n# Load new LR and HR images for SRGAN (RGB format)\nnew_lr_images = load_images_rgb(new_lr_dir, (64,64))\nnew_hr_images = load_images_rgb(new_hr_dir, (256,256))\n\n# Evaluate on new dataset (using your evaluate_gan function)\nnew_gan_metrics = evaluate_gan(generator, new_lr_images, new_hr_images)\n\n# Print side-by-side performance comparison in text\norig_psnr = np.mean(gan_metrics['psnr'])\norig_ssim = np.mean(gan_metrics['ssim'])\norig_mse  = np.mean(gan_metrics['mse'])\n\nnew_psnr = np.mean(new_gan_metrics['psnr'])\nnew_ssim = np.mean(new_gan_metrics['ssim'])\nnew_mse  = np.mean(new_gan_metrics['mse'])\n\nprint(\"\\n==================== SRGAN PERFORMANCE COMPARISON ====================\")\nprint(f\"{'Metric':<8} | {'Original':>10} | {'New':>10} | {'Diff':>10}\")\nprint(\"-\"*56)\nfor name, o_val, n_val in zip([\"PSNR\", \"SSIM\", \"MSE\"], [orig_psnr, orig_ssim, orig_mse], [new_psnr, new_ssim, new_mse]):\n    diff = n_val - o_val\n    print(f\"{name:<8} | {o_val:10.4f} | {n_val:10.4f} | {diff:10.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:47:23.460902Z","iopub.execute_input":"2025-02-17T18:47:23.461215Z","iopub.status.idle":"2025-02-17T18:47:26.356447Z","shell.execute_reply.started":"2025-02-17T18:47:23.461192Z","shell.execute_reply":"2025-02-17T18:47:26.355557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Bar Charts\n\nplt.figure(figsize=(12,5))\nmetrics = [\"PSNR\",\"SSIM\",\"MSE\"]\norig_data = [orig_psnr, orig_ssim, orig_mse]\nnew_data  = [new_psnr, new_ssim, new_mse]\ncolors = [\"blue\",\"orange\"]\n\nfor i, (metric, orig_val, new_val) in enumerate(zip(metrics, orig_data, new_data)):\n    plt.subplot(1,3,i+1)\n    plt.bar([\"Original\",\"New\"], [orig_val,new_val], color=colors)\n    plt.title(f\"{metric} Comparison\")\n    plt.ylabel(metric)\n\nplt.suptitle(\"SRGAN Metric Comparison\", fontsize=14)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T18:47:29.044409Z","iopub.execute_input":"2025-02-17T18:47:29.044770Z","iopub.status.idle":"2025-02-17T18:47:29.453686Z","shell.execute_reply.started":"2025-02-17T18:47:29.044739Z","shell.execute_reply":"2025-02-17T18:47:29.452830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}